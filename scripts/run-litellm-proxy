#!/bin/bash
# macOS wrapper for litellm that ensures Python 3.11 environment
set -e

# Source environment file for DB connection URL
if [[ -f "$HOME/.config/run-claude/.envrc" ]]; then
  source "$HOME/.config/run-claude/.envrc"
fi

LITELLM_HOME="${HOME}/.local/share/litellm"
VENV="${LITELLM_HOME}/.venv"
export LD_LIBRARY_PATH=$NIX_LD_LIBRARY_PATH

# Path to run-claude package for custom callbacks (provider compatibility)
# Set via environment or default to common locations
RUN_CLAUDE_PKG_PATH="${RUN_CLAUDE_PKG_PATH:-}"
if [[ -z "$RUN_CLAUDE_PKG_PATH" ]]; then
  # Try common locations
  for path in "$HOME/github/infra/run-claude" "$HOME/.local/src/run-claude" "/opt/run-claude"; do
    if [[ -f "$path/pyproject.toml" ]]; then
      RUN_CLAUDE_PKG_PATH="$path"
      break
    fi
  done
fi

# Marker file to track run_claude installation
RUN_CLAUDE_MARKER="${VENV}/.run_claude_installed"

if [[ ! -d "$VENV" ]]; then
  echo "Setting up litellm environment with Python 3.13..."
  mkdir -p "$LITELLM_HOME"
  uv venv --python 3.13 "$VENV"
  source "$VENV/bin/activate"
  uv pip install 'litellm[proxy]' litellm-proxy-extras psycopg2-binary prometheus_client opentelemetry-api opentelemetry-sdk
  uv pip install prisma

  # Install run_claude for custom callbacks (provider compatibility for Groq, Cerebras, etc.)
  if [[ -n "$RUN_CLAUDE_PKG_PATH" && -d "$RUN_CLAUDE_PKG_PATH" ]]; then
    echo "Installing run_claude from: $RUN_CLAUDE_PKG_PATH"
    uv pip install -e "$RUN_CLAUDE_PKG_PATH"
    echo "$RUN_CLAUDE_PKG_PATH" > "$RUN_CLAUDE_MARKER"
  else
    echo "Warning: run_claude package not found. Custom callbacks will not be available."
    echo "Set RUN_CLAUDE_PKG_PATH to enable provider compatibility callbacks."
  fi

  # Create a modified schema.prisma with explicit output path to the venv
  LITELLM_SCHEMA="$(python -c 'import litellm; print(litellm.__path__[0])')/proxy/schema.prisma"
  PRISMA_OUTPUT="${VENV}/lib/python3.13/site-packages/prisma"
  LOCAL_SCHEMA="${LITELLM_HOME}/schema2.prisma"


  # Copy and patch the schema to specify correct output
 sed 's|generator client {|generator client {\n  output = "'"${PRISMA_OUTPUT}"'"|' "$LITELLM_SCHEMA" > "$LOCAL_SCHEMA"


  # Generate prisma client locally
  python -m prisma generate --schema "$LOCAL_SCHEMA"

  # Run prisma db push via Docker (avoids native binary issues on NixOS)
  docker run --rm \
    --network host \
    --entrypoint prisma \
    -e DATABASE_URL="$DATABASE_URL" \
    -v "$LOCAL_SCHEMA:/app/schema.prisma" \
    ghcr.io/berriai/litellm:main-latest \
    db push --schema /app/schema.prisma --skip-generate


else
  source "$VENV/bin/activate"

  # Check if run_claude needs to be installed/updated
  if [[ -n "$RUN_CLAUDE_PKG_PATH" && -d "$RUN_CLAUDE_PKG_PATH" ]]; then
    CURRENT_PATH=""
    [[ -f "$RUN_CLAUDE_MARKER" ]] && CURRENT_PATH="$(cat "$RUN_CLAUDE_MARKER")"
    if [[ "$CURRENT_PATH" != "$RUN_CLAUDE_PKG_PATH" || ! -f "$RUN_CLAUDE_MARKER" ]]; then
      echo "Installing/updating run_claude from: $RUN_CLAUDE_PKG_PATH"
      uv pip install -e "$RUN_CLAUDE_PKG_PATH"
      echo "$RUN_CLAUDE_PKG_PATH" > "$RUN_CLAUDE_MARKER"
    fi
  fi

  # Create a modified schema.prisma with explicit output path to the venv
  LITELLM_SCHEMA="$(python -c 'import litellm; print(litellm.__path__[0])')/proxy/schema.prisma"
  PRISMA_OUTPUT="${VENV}/lib/python3.13/site-packages/prisma"
  LOCAL_SCHEMA="${LITELLM_HOME}/schema2.prisma"


  # Copy and patch the schema to specify correct output
  sed 's|generator client {|generator client |\n  output = "'"${PRISMA_OUTPUT}"'"|' "$LITELLM_SCHEMA" > "$LOCAL_SCHEMA"


  # Generate prisma client locally
  python -m prisma generate --schema "$LOCAL_SCHEMA"

fi

exec "$VENV/bin/litellm" "$@"
