# Base model definitions for run-claude
# These are the built-in model definitions that can be overridden by user definitions
# in ~/.config/run-claude/models.yaml
#
# Model names should be unique and descriptive

model_list:
  # ==========================================================================
  # Anthropic
  # ==========================================================================
  - model_name: "claude-opus-4-20250514"
    litellm_params:
      model: anthropic/claude-opus-4-20250514
      api_key: os.environ/ANTHROPIC_API_KEY

  - model_name: "claude-sonnet-4-20250514"
    litellm_params:
      model: anthropic/claude-sonnet-4-20250514
      api_key: os.environ/ANTHROPIC_API_KEY

  - model_name: "claude-3-5-haiku-20241022"
    litellm_params:
      model: anthropic/claude-3-5-haiku-20241022
      api_key: os.environ/ANTHROPIC_API_KEY

  # ==========================================================================
  # OpenAI
  # ==========================================================================
  - model_name: "openai-gpt4"
    litellm_params:
      model: openai/gpt-4.1
      api_key: os.environ/OPENAI_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "openai-gpt4o"
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "openai-gpt4o-mini"
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "openai-o1"
    litellm_params:
      model: openai/o1
      api_key: os.environ/OPENAI_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "openai-o3-mini"
    litellm_params:
      model: openai/o3-mini
      api_key: os.environ/OPENAI_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  # ==========================================================================
  # Gemini
  # ==========================================================================
  - model_name: "gemini-pro"
    litellm_params:
      model: gemini/gemini-2.5-pro-preview-06-05
      api_key: os.environ/GEMINI_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "gemini-flash"
    litellm_params:
      model: gemini/gemini-2.5-flash-preview-05-20
      api_key: os.environ/GEMINI_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "gemini-flash-lite"
    litellm_params:
      model: gemini/gemini-2.0-flash-lite
      api_key: os.environ/GEMINI_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "gemini-thinking"
    litellm_params:
      model: gemini/gemini-2.5-flash-preview-04-17-thinking
      api_key: os.environ/GEMINI_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  # ==========================================================================
  # Cerebras
  # ==========================================================================
  # gpt-oss-120b
  - model_name: "cerebras/gpt-oss-120b"
    litellm_params:
      model: gpt-oss-120b
      api_key: os.environ/CEREBRAS_API_KEY
      api_base: https://api.cerebras.ai/v1
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "cerebras/gpt-oss-120b:instant"
    litellm_params:
      model: gpt-oss-120b
      api_key: os.environ/CEREBRAS_API_KEY
      api_base: https://api.cerebras.ai/v1
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "cerebras/gpt-oss-120b:thinking"
    litellm_params:
      model: gpt-oss-120b
      api_key: os.environ/CEREBRAS_API_KEY
      api_base: https://api.cerebras.ai/v1
      drop_params: true
      additional_drop_params: ["context_management"]
      reasoning_effort: "low"

  - model_name: "cerebras/gpt-oss-120b:thinking-medium"
    litellm_params:
      model: gpt-oss-120b
      api_key: os.environ/CEREBRAS_API_KEY
      api_base: https://api.cerebras.ai/v1
      drop_params: true
      additional_drop_params: ["context_management"]
      reasoning_effort: "medium"

  - model_name: "cerebras/gpt-oss-120b:thinking-high"
    litellm_params:
      model: gpt-oss-120b
      api_key: os.environ/CEREBRAS_API_KEY
      api_base: https://api.cerebras.ai/v1
      drop_params: true
      additional_drop_params: ["context_management"]
      reasoning_effort: "high"

  # llama-3.3-70b
  - model_name: "cerebras/llama-3.3-70b"
    litellm_params:
      model: llama-3.3-70b
      api_key: os.environ/CEREBRAS_API_KEY
      api_base: https://api.cerebras.ai/v1
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  # llama3.1-8b
  - model_name: "cerebras/llama3.1-8b"
    litellm_params:
      model: llama3.1-8b
      api_key: os.environ/CEREBRAS_API_KEY
      api_base: https://api.cerebras.ai/v1
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  # qwen-3-235b-a22b-instruct-2507
  - model_name: "cerebras/qwen-3-235b-a22b-instruct-2507"
    litellm_params:
      model: qwen-3-235b-a22b-instruct-2507
      api_key: os.environ/CEREBRAS_API_KEY
      api_base: https://api.cerebras.ai/v1
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  # qwen-3-32b
  - model_name: "cerebras/qwen-3-32b"
    litellm_params:
      model: qwen-3-32b
      api_key: os.environ/CEREBRAS_API_KEY
      api_base: https://api.cerebras.ai/v1
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  # zai-glm-4.7
  - model_name: "cerebras/zai-glm-4.7"
    litellm_params:
      model: zai-glm-4.7
      api_key: os.environ/CEREBRAS_API_KEY
      api_base: https://api.cerebras.ai/v1
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "cerebras/zai-glm-4.7:instant"
    litellm_params:
      model: cerebras/zai-glm-4.7
      api_key: os.environ/CEREBRAS_API_KEY
      api_base: https://api.cerebras.ai/v1
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "cerebras/zai-glm-4.7:thinking"
    litellm_params:
      model: cerebras/zai-glm-4.7
      api_key: os.environ/CEREBRAS_API_KEY
      api_base: https://api.cerebras.ai/v1
      drop_params: true
      additional_drop_params: ["context_management"]
      reasoning_effort: "low"

  - model_name: "cerebras/zai-glm-4.7:thinking-medium"
    litellm_params:
      model: cerebras/zai-glm-4.7
      api_key: os.environ/CEREBRAS_API_KEY
      api_base: https://api.cerebras.ai/v1
      drop_params: true
      additional_drop_params: ["context_management"]
      reasoning_effort: "medium"

  - model_name: "cerebras/zai-glm-4.7:thinking-high"
    litellm_params:
      model: cerebras/zai-glm-4.7
      api_key: os.environ/CEREBRAS_API_KEY
      api_base: https://api.cerebras.ai/v1
      drop_params: true
      additional_drop_params: ["context_management"]
      reasoning_effort: "high"

  # cerebras/pro - alias for zai-glm-4.7 with subscription key
  - model_name: "cerebras_pro"
    litellm_params:
      model: cerebras/zai-glm-4.7
      api_key: os.environ/CEREBRAS_SUB_KEY
      api_base: https://api.cerebras.ai/v1
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "cerebras_pro_instant"
    litellm_params:
      model: cerebras/zai-glm-4.7
      api_key: os.environ/CEREBRAS_SUB_KEY
      api_base: https://api.cerebras.ai/v1
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

# Named

  - model_name: "cerebras-pro/haiku"
    litellm_params:
      model: cerebras/zai-glm-4.7
      api_key: os.environ/CEREBRAS_SUB_KEY
      api_base: https://api.cerebras.ai/v1
      drop_params: true
      additional_drop_params: ["context_management"]
      reasoning_effort: "low"

  - model_name: "cerebras-pro/sonnet"
    litellm_params:
      model: cerebras/zai-glm-4.7
      api_key: os.environ/CEREBRAS_SUB_KEY
      api_base: https://api.cerebras.ai/v1
      drop_params: true
      additional_drop_params: ["context_management"]
      reasoning_effort: "medium"

  - model_name: "cerebras-pro/opus"
    litellm_params:
      model: cerebras/zai-glm-4.7
      api_key: os.environ/CEREBRAS_SUB_KEY
      api_base: https://api.cerebras.ai/v1
      drop_params: true
      additional_drop_params: ["context_management"]
      reasoning_effort: "high"

# Zai - Named


  - model_name: "zai/haiku"
    litellm_params:
      model: zai/glm-4.7
      api_key: os.environ/ZAI_API_KEY
      drop_params: true
      additional_drop_params: ["context_management"]
      reasoning_effort: "low"

  - model_name: "zai/sonnet"
    litellm_params:
      model: zai/glm-4.7
      api_key: os.environ/ZAI_API_KEY
      drop_params: true
      additional_drop_params: ["context_management"]
      reasoning_effort: "medium"

  - model_name: "zai/opus"
    litellm_params:
      model: zai/glm-4.7
      api_key: os.environ/ZAI_API_KEY
      drop_params: true
      additional_drop_params: ["context_management"]
      reasoning_effort: "high"

  # Alias for zai/opus - high quality
  - model_name: "ultra"
    litellm_params:
      model: zai/glm-4.7
      api_key: os.environ/ZAI_API_KEY
      drop_params: true
      additional_drop_params: ["context_management"]
      reasoning_effort: "high"

  # Alias for zai/opus - cheap option
  - model_name: "cheap"
    litellm_params:
      model: zai/glm-4.7
      api_key: os.environ/ZAI_API_KEY
      drop_params: true
      additional_drop_params: ["context_management"]
      reasoning_effort: "high"




# Groq - Named



# Groq GPT-OSS based (same model, different reasoning effort)

# Groq - Named (GPT-OSS supports reasoning_effort: low/medium/high)
  - model_name: "groq/haiku"
    litellm_params:
      model: groq/openai/gpt-oss-20b
      api_key: os.environ/GROQ_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]
      reasoning_effort: "low"

  - model_name: "groq/sonnet"
    litellm_params:
      model: groq/openai/gpt-oss-120b
      api_key: os.environ/GROQ_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]
      reasoning_effort: "medium"

  - model_name: "groq/opus"
    litellm_params:
      model: groq/openai/gpt-oss-120b
      api_key: os.environ/GROQ_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]
      reasoning_effort: "high"

  # Alias for groq/opus - fast option
  - model_name: "fast"
    litellm_params:
      model: groq/openai/gpt-oss-120b
      api_key: os.environ/GROQ_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]
      reasoning_effort: "high"

# Groq Extended Models
  # Kimi: does NOT support reasoning_effort - must drop
  - model_name: "groq-kimi-k2"
    litellm_params:
      model: groq/moonshotai/kimi-k2-instruct-0905
      api_key: os.environ/GROQ_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking", "reasoning_effort"]

  # Llama 4: does NOT support reasoning_effort - must drop
  - model_name: "groq-llama-4-scout"
    litellm_params:
      model: groq/meta-llama/llama-4-scout-17b-16e-instruct
      api_key: os.environ/GROQ_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking", "reasoning_effort"]

  - model_name: "groq-llama-4-maverick"
    litellm_params:
      model: groq/meta-llama/llama-4-maverick-17b-128e-instruct
      api_key: os.environ/GROQ_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking", "reasoning_effort"]

  # Qwen3: supports reasoning_effort but ONLY "default" or "none" - drop to avoid invalid values
  - model_name: "groq-qwen3-32b"
    litellm_params:
      model: groq/qwen/qwen3-32b
      api_key: os.environ/GROQ_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking", "reasoning_effort"]

  # Llama 3.x: does NOT support reasoning_effort - must drop
  - model_name: "groq-llama-3.3-70b"
    litellm_params:
      model: groq/llama-3.3-70b-versatile
      api_key: os.environ/GROQ_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking", "reasoning_effort"]

  - model_name: "groq-llama-3.1-8b"
    litellm_params:
      model: groq/llama-3.1-8b-instant
      api_key: os.environ/GROQ_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking", "reasoning_effort"]







  # ==========================================================================
  # Groq
  # ==========================================================================
  # Qwen3: only supports "default" or "none" - drop to avoid invalid values
  - model_name: "groq.qwen3-32b"
    litellm_params:
      model: groq/qwen/qwen3-32b
      api_key: os.environ/GROQ_API_KEY
      api_base: https://api.groq.com/openai/v1
      drop_params: true
      additional_drop_params: ["context_management", "thinking", "reasoning_effort"]

  # Kimi: does NOT support reasoning_effort
  - model_name: "groq.kimi-k2-instruct"
    litellm_params:
      model: groq/moonshotai/kimi-k2-instruct
      api_key: os.environ/GROQ_API_KEY
      api_base: https://api.groq.com/openai/v1
      drop_params: true
      max_tokens: 4194
      additional_drop_params: ["context_management", "thinking", "reasoning_effort"]

  # GPT-OSS: supports reasoning_effort with low/medium/high
  - model_name: "groq.gpt-oss-120b"
    litellm_params:
      model: groq/openai/gpt-oss-120b
      api_key: os.environ/GROQ_API_KEY
      api_base: https://api.groq.com/openai/v1
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]
      reasoning_effort: "medium"

  # Llama 3.x: does NOT support reasoning_effort
  - model_name: "groq.llama-3.3-70b"
    litellm_params:
      model: groq/meta-llama/llama-3.3-70b-versatile
      api_key: os.environ/GROQ_API_KEY
      api_base: https://api.groq.com/openai/v1
      drop_params: true
      additional_drop_params: ["context_management", "thinking", "reasoning_effort"]

  # ==========================================================================
  # Azure OpenAI
  # ==========================================================================
  - model_name: "azure-gpt4"
    litellm_params:
      model: azure/gpt-4.1
      api_key: os.environ/AZURE_OPENAI_API_KEY
      api_base: os.environ/AZURE_OPENAI_ENDPOINT
      api_version: os.environ/AZURE_OPENAI_API_VERSION
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "azure-gpt4o"
    litellm_params:
      model: azure/gpt-4o
      api_key: os.environ/AZURE_OPENAI_API_KEY
      api_base: os.environ/AZURE_OPENAI_ENDPOINT
      api_version: os.environ/AZURE_OPENAI_API_VERSION
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "azure-gpt4o-mini"
    litellm_params:
      model: azure/gpt-4o-mini
      api_key: os.environ/AZURE_OPENAI_API_KEY
      api_base: os.environ/AZURE_OPENAI_ENDPOINT
      api_version: os.environ/AZURE_OPENAI_API_VERSION
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  # ==========================================================================
  # xAI Grok
  # ==========================================================================
  - model_name: "grok-2"
    litellm_params:
      model: xai/grok-2-latest
      api_key: os.environ/GROK_API_KEY
      api_base: https://api.x.ai/v1
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "grok-2-mini"
    litellm_params:
      model: xai/grok-2-vision-latest
      api_key: os.environ/GROK_API_KEY
      api_base: https://api.x.ai/v1
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "grok-vision"
    litellm_params:
      model: xai/grok-2-vision-latest
      api_key: os.environ/GROK_API_KEY
      api_base: https://api.x.ai/v1
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  # ==========================================================================
  # DeepSeek
  # ==========================================================================
  - model_name: "deepseek-reasoner"
    litellm_params:
      model: deepseek/deepseek-reasoner
      api_key: os.environ/DEEPSEEK_API_KEY
      api_base: https://api.deepseek.com/v1
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "deepseek-chat"
    litellm_params:
      model: deepseek/deepseek-chat
      api_key: os.environ/DEEPSEEK_API_KEY
      api_base: https://api.deepseek.com/v1
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "deepseek-coder"
    litellm_params:
      model: deepseek/deepseek-coder
      api_key: os.environ/DEEPSEEK_API_KEY
      api_base: https://api.deepseek.com/v1
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  # ==========================================================================
  # Mistral
  # ==========================================================================
  - model_name: "mistral-large"
    litellm_params:
      model: mistral/mistral-large-latest
      api_key: os.environ/MISTRAL_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "mistral-medium"
    litellm_params:
      model: mistral/mistral-medium-latest
      api_key: os.environ/MISTRAL_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "mistral-small"
    litellm_params:
      model: mistral/mistral-small-latest
      api_key: os.environ/MISTRAL_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "codestral"
    litellm_params:
      model: mistral/codestral-latest
      api_key: os.environ/MISTRAL_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "mistral-nemo"
    litellm_params:
      model: mistral/open-mistral-nemo
      api_key: os.environ/MISTRAL_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  # ==========================================================================
  # Perplexity
  # ==========================================================================
  - model_name: "perplexity-large"
    litellm_params:
      model: perplexity/sonar-pro
      api_key: os.environ/PERPLEXITY_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "perplexity-medium"
    litellm_params:
      model: perplexity/sonar
      api_key: os.environ/PERPLEXITY_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "perplexity-fast"
    litellm_params:
      model: perplexity/sonar
      api_key: os.environ/PERPLEXITY_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "perplexity-reasoning"
    litellm_params:
      model: perplexity/sonar-reasoning-pro
      api_key: os.environ/PERPLEXITY_API_KEY
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  # ==========================================================================
  # Local (Ollama / vLLM / LM Studio)
  # ==========================================================================

  - model_name: "spark/gpt-120"
    litellm_params:
      model: openai/llama
      api_base: http://localhost:7180/v1
      api_key: fake-key  #

  - model_name: "local-large"
    litellm_params:
      model: ollama/llama3.3:70b
      api_base: http://localhost:11434
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "local-medium"
    litellm_params:
      model: ollama/qwen2.5:32b
      api_base: http://localhost:11434
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "local-small"
    litellm_params:
      model: ollama/qwen2.5:7b
      api_base: http://localhost:11434
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "vllm-large"
    litellm_params:
      model: openai/llama-3.3-70b
      api_base: http://localhost:8000/v1
      api_key: "not-needed"
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "lmstudio"
    litellm_params:
      model: openai/local-model
      api_base: http://localhost:1234/v1
      api_key: "lm-studio"
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "local-coder"
    litellm_params:
      model: ollama/qwen2.5-coder:32b
      api_base: http://localhost:11434
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]

  - model_name: "local-deepseek-coder"
    litellm_params:
      model: ollama/deepseek-coder-v2:16b
      api_base: http://localhost:11434
      drop_params: true
      additional_drop_params: ["context_management", "thinking"]
